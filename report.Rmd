---
title: "Predicting Heart Disease Mortality"
author: "David Edelman"
date: "February 28, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(data.table)
library(ggplot2)
library(gridExtra)
library(grid)
path <- "/Users/edelmans/Documents/MSCapstone/"
#path <- "C:/users/dedelman/desktop/capstone/"
train_df <- read.csv(file=paste0(path,"train_values.csv"),
                  header=TRUE,
                  stringsAsFactors = TRUE)

train_label <- read.csv(file=paste0(path,"train_labels.csv"),
                        header=TRUE,
                        stringsAsFactors = TRUE)

train_data <- merge(x=train_df, y=train_label, by="row_id")

#Store the high, low, mean and median values for later use
low_mort <- as.integer(min(train_data$heart_disease_mortality_per_100k))
high_mort <- as.integer(max(train_data$heart_disease_mortality_per_100k))
hd_mean = mean(train_data$heart_disease_mortality_per_100k)
hd_med = median(train_data$heart_disease_mortality_per_100k)

#Rename a typo in the data set
train_data <- train_data %>% 
  mutate(health__pct_physical_inactivity = health__pct_physical_inacticity) %>%
  select(-health__pct_physical_inacticity)

```

```{r, eval=FALSE, echo=FALSE}
train_data <- train_data %>% mutate(metro = ifelse(like(area__rucc, "Nonmetro"), "Nonmetro", "Metro"))


                                  )


```

## Executive Summary
Heart disease is one of the leading causes of death in the United States. This document presents an analysis of county-by-county heart disease mortality rates (per 100,000 individuals) and uses various demographic statistics to build a model that predicts the heart disease mortality rate for that county

The given data set, containing known heart disease mortality rates, comprises 3198 observations, representing 1599 counties and data collected over two separate years.  Both categorical and numeric data are present in the feature set, and after some initial data exploration, several other features were calculated. A predictive regression model was then created using select features in order to predict the heart disease mortality rate of 3080 county/year pairs, representing 1540 distinct counties.

While building and tuning the predictive model, the following features were deemed significant to the predictive power of the model:


### Area Information
* Area RUCC (Rural-Urban Continuum Codes) – classifies each county into one of 9 mutually exclusive categories that identifies (a) the population size, (b) the degree of urbanization and (c) proximity to a metropolitan area.
    + While the RUCC itself did now show any strong correlation to heart disease mortality rate, by combining one or more RUCC values into one of 5 groups based solely on population size, the data showed 3 population groups that skewed below the mean heart disease mortality rate and 1 that skewed above the mean.
    + Additionally, classifying the RUCC values into another calculated feature as “Metro” or “Non-Metro” showed the data being skewed below the mean for Metro and above the men for Non-Metro, adding an enhancement to the predictive model (data source: USDA Economic Research Service)

### Economic Factors
* Economic Typology – classifies each county into one of 6 mutually exclusive categories of economic dependence; two categories show a distribution skewed below the mean heart disease mortality rate and two categories are skewed above (source: USDA Economic Research Service).
* Percent of Civilian Labor – the annualized percent of  the county’s population classified as civilian; analysis shows a moderate negative correlation to heart disease mortality rate (source: Bureau of Labor Statistics)

### Demographics
* Percent of non-Hispanic African Americans – analysis shows the strongest positive correlation among the 5 race/ethnicity groups (source: US Census Population Estimates)
* Percent of adults with less than a high-school diploma; percent of adults with a Bachelor’s degree (or higher) – the former shows a strong positive correlation, while the latter shows an equally strong negative correlation (source: US Census Population Estimates)

### Health Factors
* Air Pollution Particulate Matter – measured in µg/m3; the average concentration of fine particulate matter as measured over the year. Lower concentrations skewed below the population mean while higher concentrations skewed above (source: CDC WONDER).
* Percent of physical inactivity – percent of adult population that self-identifies as physically inactive (source: National Center for Chronic Disease Prevention and Health Promotion); physical inactivity showed a moderately strong correlation to heart disease mortality rate
* Percent of adult obesity; percent of diabetes; percent of adult smoking – each of the three factors individually showed a strong correlation with heart disease mortality rate, but with a thought experiment and some data transformation into combined factors, an even stronger correlation was found (sources NCCDPHP; NCCDPHP, Division of Diabetes Translation; Behavioral Risk Factor Surveillance System)
* Homicide, Motor Vehicle Death rates per 100,000 – two separate death rates (per 100,000 individuals); by scaling each rate to a logarithmic scale (base 10), a strong correlation to heart disease mortality rate was found (source: National Center for Health Statistics)

## Data Exploration and Initial Analysis
### Heart Disease Mortality Rate
#### Descriptive Statistics
Heart Disease Mortality Rate (herein shown with a unit of “deaths per 100,000 population”) in the given data set showed a mean of 279.4, median of 275.0, and standard deviation of 59.0 with a range of 109.0 – 512.0, across 3198 observations. A histogram with 40 equal bins (calculated based on the minimum and maximum values) and a box plot both show that heart disease mortality rate is approximately normal (skewed very slightly positive), with only approximately 10-15 outliers (values outside of the Inner Quartile Range of 237 – 317).

```{r}
#Histogram & boxplot
train_data %>% ggplot(aes(x=heart_disease_mortality_per_100k))+geom_histogram(bins=40)+
  xlab("heart_mort_100k")+
  geom_vline(linetype = "dashed", color = "purple", xintercept = hd_med)+
  geom_vline(linetype = "dashed", color = "blue", xintercept = hd_mean)+
  annotate("text", x=hd_mean+20, y=250, label="<- mean", size=3, color = "blue")+
  annotate("text", x=hd_med-20, y=250, label="median ->", size=3, color = "purple")  

train_data %>% ggplot(aes(y=heart_disease_mortality_per_100k))+geom_boxplot()+
  geom_hline(linetype = "dashed", color = "blue", yintercept = hd_mean)+
  theme(axis.text.x=element_blank())
```

#### Initial Analysis of Predictors
##### Predictor Types
The data set includes 32 values for each rows (ignoring "row_id"), 29 of which are numeric

```{r}
#Numeric columns
num_cols <- train_data %>% 
  select(-c(row_id, heart_disease_mortality_per_100k)) %>%
  .[sapply(., is.numeric)] %>% 
  colnames()

#Categorical columns
cat_cols <- colnames(train_data)[sapply(train_data, is.factor)]

length(num_cols)
length(cat_cols)
```

(the column "yr" will also be ignored as it has 2 values, "a" and "b", which are merely placeholders)

##### Missing feature values
In a data set of this size, missing data can adversely affect the predictive value of individual features, so we look for any features that have a significant percentage of missing data

```{r}
#What percentage of rows have NA values for all features?
NAs <- data.frame(
  features = colnames(train_data %>% select(-heart_disease_mortality_per_100k, -yr, -row_id)),
  NA_pct = 
      format(sapply(train_data %>%
                      select(-heart_disease_mortality_per_100k,
                             -yr, -row_id),
             function(x){mean(ifelse(is.na(x), 1, 0))},
             simplify=TRUE)*100, digits=3) 
) 

#Show NA percentage from highest to lowest
NAs %>% arrange(desc(NA_pct))
```

We will remove predictors from the data set that have more than 10% missing values. This turns out to be
*health__homicides_per_100k
*health__pct_excessive_drinking
*health__pct_adult_smoking
*health__motor_vehicle_crash_deaths_per_100k

```{r}
#Remove high NA features
high_NA <- NAs %>% 
  filter(NA_pct > 10) %>% 
  .$features %>% 
  as.character()

train_data <- train_data %>% select(-high_NA)
```

12 predictors have 0.0625% missing values, which equates to 2 rows. If it is the same two rows that are missing all of the predictors, we will just remove those rows from the data set.

```{r}
#Which features have minimum number of NAs (> 0)
min_missing <- min(NAs %>% filter(NA_pct > 0) %>% select(NA_pct))  
NA2 <- sapply(train_data %>% 
        select(as.vector(NAs$features[NAs$NA_pct == min_missing])),
       function(x){which(is.na(x))}, simplify=TRUE)
t(NA2)
```

We see that index 1090 and 1251 are missing all of the selected predictors, so we will remove them from the data set

```{r}
#Remove the rows with 12 NA predictors
train_data <- train_data[-t(NA2)[1,c(1:2)], ]
```

For the remaining NA values, we will decide how to handle after some exploratory data analysis of the features.

#### Distributions Across Categorical Features
##### Economic Typology
The 6 economic typologies used by the USDA Economic Research Service to assign to each county are

*Farm-dependent
*Federal/State government-dependent
*Manufacturing-dependent
*Mining-dependent
*Non-specialized
*Recreation

The typologies speak to the main type of industries of a particular county. So while we don’t have the specific industries in each county (knowing, intellectually, that certain industries have been linked in the past to specific conditions, including heart disease), we can use the typology as a good representative proxy for specific industries. To identify any potential relationship between typology and heart disease mortality, we use histograms and box plots to examine each typology for an abnormal or skewed distribution.

```{r}
#Histograms for economic type
train_data %>% ggplot(aes(x=heart_disease_mortality_per_100k))+
              xlab("heart_mort_100k")+
              geom_histogram(binwidth = (high_mort-low_mort)/50)+
              facet_wrap(~ econ__economic_typology, ncol = 3)+
              geom_vline(linetype="dashed", xintercept = hd_mean, color = "blue")+
              geom_vline(linetype="dashed", xintercept = hd_med, color = "red")+
              ggtitle("Economic Typology")+theme(plot.title = element_text(hjust=0.5))+
              annotate("text", x=hd_mean+40, y=100, label="<- mean", size=2.5, color = "blue")+
              annotate("text", x=hd_med-40, y=100, label="median ->", size=2.5, color = "red")

#Box plot by economic type
train_data %>% ggplot(aes(x=econ__economic_typology, y=heart_disease_mortality_per_100k))+
        geom_boxplot() + 
        geom_hline(linetype="dashed", yintercept = hd_mean, color = "blue")+xlab("")+
        geom_hline(linetype="dashed", yintercept = hd_med, color = "red")+
        theme(axis.text.x = element_text(angle = 45, hjust=1, vjust=1)) + 
        ggtitle("Economic Typology")+theme(plot.title = element_text(hjust=0.5))+
        annotate("text", x=.5, y=hd_mean+30, label="mean", size=3, color = "blue", angle=90)+
        annotate("text", x=6.5, y=hd_med-30, label="median", size=3, color = "red", angle=90)

```

The histograms show that all of the typologies appear to be approximately normal. They also show that the mean from Recreation and from Farm-dependent (to a lesser degree) to be lower than the population mean. None of the typologies appear to have significantly higher means than the population average.  However, the box plots give a better picture of the distributions, showing that indeed Recreation and Farm-Dependent have their median value below the population average, while Manufacturing-dependent and Mining-dependent have medians well above the population average (Non-specialized shows a very slight variation from the population mean and median).  The same results are shown below:

```{r, warning=FALSE}
#Show category mean/median and comparison to population
bind_rows(train_data %>% select(heart_disease_mortality_per_100k,
                      econ__economic_typology) %>%
  group_by(econ__economic_typology) %>%
  summarize(mn = mean(heart_disease_mortality_per_100k),
            md = median(heart_disease_mortality_per_100k)) %>%
  mutate(MeanAboveBelow = ifelse(round(mn,1) < round(hd_mean,1), 
                              "Below",
                             ifelse(round(mn,1) = round(hd_mean,1),
                              "Equal", "Above")),
         MedianAboveBelow = ifelse(round(md,1) < round(hd_med,1),
                               "Below",
                             ifelse(round(md,1) = round(hd_med,1),
                              "Equal", "Above")))%>%
  select(econ__economic_typology, mn, 
         MeanAboveBelow, md, MedianAboveBelow)
  , data.frame(econ__economic_typology = "Population",
               mn= hd_mean, 
               MeanAboveBelow = "",
               md = hd_med,
               MedianAboveBelow = "")
)
```

Due to heart disease mortality rates being distributed differently across the economic typologies, this feature is a good candidate for use in a predictive model.

##### Population Spread
The individual values for “Area_RUCC” have populations ranging from < 100 to > 600, and histograms show that many distributions do not appear to be approximately normal.

```{r}
#Rename original levels to show on plots
levels(train_data$area__rucc) <- c("Metro - 1 Million +",
                        "Metro - 250,000 to 1 Mil",
                        "Metro - less than 250,000",
                        "Nonmetro - Rural or < 2.5k, adjacent",
                        "Nonmetro - Rural or < 2.5k, non-adjacent",
                        "Nonmetro - 2,500 to 19,999, adjacent",
                        "Nonmetro - 2,500 to 19,999, non-adjacent",
                        "Nonmetro - 20,000 or more, adjacent",
                        "Nonmetro - 20,000 or more, non-adjacent")

#Histrograms of area__rucc
train_data %>% ggplot(aes(x=heart_disease_mortality_per_100k))+
  xlab("heart_mort_100k")+
  geom_histogram(binwidth = (high_mort-low_mort)/40)+
  facet_wrap(~ area__rucc, ncol = 3)+
  geom_vline(linetype="dashed", xintercept = hd_mean, color = "blue")+
  geom_vline(linetype="dashed", xintercept = hd_med, color = "red")+
  annotate("text", x=hd_mean+40, y=55, label="<- mean", size=2.5, color = "blue")+
  annotate("text", x=hd_med-40, y=55, label="median ->", size=2.5, color = "red")
```

However, we can transform them into population groups as a proxy for Area_RUCC. The transformation is 

--maybe stuff with knitr or gridextra instead--
```{r, echo=FALSE, warning=FALSE, message=FALSE}
#Show area_rucc level mapping to population
lvl <- levels(train_data$area__rucc)
pop_lvl <- c("1M+", "250k-1M", "20-250K", "under 2,500", "under 2,500", "2.5-20K", "2.5-20k", "20-250K", "20-250K")

rucc_tab <- data.frame(Area_RUCC=lvl, Population=pop_lvl)

grid.table(rucc_tab)
```

```{r}
#Add "population" column using mapping
#Note - 2 different patterns map to 20-250k
train_data <- train_data %>% 
  mutate(population = ifelse(like(train_data$area__rucc,
                                  "19,999"), "2.5-20k",
                      ifelse(like(train_data$area__rucc,
                                  "2.5k"), "under 2.5k",
                      ifelse(like(train_data$area__rucc,
                                  "20,000"), "20-250k",
                      ifelse(like(train_data$area__rucc,
                                  "fewer than 250,000"), "20-250k",
                      ifelse(like(train_data$area__rucc,
                                  "250,000"), "250k-1M",
                         "1M+"))))))

#Force population into a factor
train_data$population <- factor(train_data$population, 
                                levels=c("under 2.5k",
                                         "2.5-20k",
                                         "20-250k",
                                         "250k-1M", "1M+"))

```

Looking at the histograms we now see a more even spread of data and more normal distributions.

```{r}
#Histograms by population groups
train_data %>% ggplot(aes(x=heart_disease_mortality_per_100k))+
  xlab("heart_mort_100k")+
  geom_histogram(binwidth = (high_mort-low_mort)/40)+
  facet_wrap(~ population, ncol = 3)+
  geom_vline(linetype="dashed", xintercept = hd_mean, color = "blue")+
  geom_vline(linetype="dashed", xintercept = hd_med, color = "red")+
  annotate("text", x=hd_mean+40, y=75, label="<- mean", size=2.5, color = "blue")+
  annotate("text", x=hd_med-40, y=75, label="median ->", size=2.5, color = "red")
```

The “2.5-20K” group appears to be skewed somewhat positive, while the “1M+” group is skewed negative, even though the peak is below the population mean and median. Box plots show the distributions more cleanly.

```{r}
#Box plot by population group
train_data %>%
  ggplot(aes(x=population, y=heart_disease_mortality_per_100k))+
  xlab("")+
  geom_boxplot() +
  geom_hline(linetype="dashed", yintercept = hd_mean, color = "blue")+
  geom_hline(linetype="dashed", yintercept = hd_med, color = "red")+
  theme(axis.text.x = element_text(angle = 45, hjust=1, vjust=1))+
  ggtitle("Population Groups")+
  annotate("text", x=.5, y=hd_mean+30, label="mean", size=3, color = "blue", angle=90)+
  annotate("text", x=5.5, y=hd_med-30, label="median", size=3, color = "red", angle=90)
```

Here we can more clearly see that the median for “under 2.5K”, “250K-1M” and “1M+” are all below the population mean and median. The group “2.5-20K” has a median well above the population mean and median, while the “20-250K” group median is only slightly higher than the population.

```{r, warning=FALSE}
bind_rows(train_data %>% select(heart_disease_mortality_per_100k,
                      population) %>%
  group_by(population) %>%
  summarize(mn = mean(heart_disease_mortality_per_100k),
            md = median(heart_disease_mortality_per_100k)) %>%
  mutate(MeanAboveBelow = ifelse(round(mn,1) < hd_mean, 
                                 "Below",
                                 ifelse(round(mn,1) == hd_mean,
                                        "Equal", "Above")),
         MedianAboveBelow = ifelse(round(md,1) < hd_med,
                                   "Below",
                                   ifelse(round(md,1) == hd_med,
                                          "Equal", "Above"))) %>%
  select(population, mn, MeanAboveBelow, md, MedianAboveBelow)
  , data.frame(population = "Population", 
               mn= hd_mean, 
               MeanAboveBelow = "",
               md = hd_med,
               MedianAboveBelow = "")
)
```

With population groups showing a different distribution for heart mortality rates, this calculated feature is another good candidate for use in a predictive model.

The analysis went one step further and grouped the RUCC values based on whether or not the county was considered to be a metropolitan area or not.  Based solely on the first word in the RUCC category title, each county was classified as either “Metro” or “Non-Metro”.

```{r}
#Group into metro/non-metro
train_data <- train_data %>% 
  mutate(metro = ifelse(like(area__rucc, "Nonmetro"), 
                        "Nonmetro", "Metro"))

#Histograms by metro type
train_data %>% ggplot(aes(x=heart_disease_mortality_per_100k))+
  xlab("heart_mort_100k")+
  geom_histogram(binwidth = (high_mort-low_mort)/40)+
  facet_wrap(~ metro, ncol = 3)+
  geom_vline(linetype="dashed", xintercept = hd_mean, color = "blue")+
  geom_vline(linetype="dashed", xintercept = hd_med, color = "red")+
  annotate("text", x=hd_mean+40, y=150, label="<- mean", size=2.5, color = "blue")+
  annotate("text", x=hd_med-40, y=150, label="median ->", size=2.5, color = "red")

#Box plot by metro_type
train_data %>% ggplot(aes(x=metro, y=heart_disease_mortality_per_100k))+
  xlab("")+
  geom_boxplot()+
  geom_hline(linetype="dashed", yintercept = hd_mean, color = "blue")+
  geom_hline(linetype="dashed", yintercept = hd_med, color = "red")+
  theme(axis.text.x = element_text(angle = 45, hjust=1, vjust=1))+
  ggtitle("Metropolitan Type")+
  annotate("text", x=.5, y=hd_mean+30, label="mean", size=3, color = "blue", angle=90)+
  annotate("text", x=2.5, y=hd_med-30, label="median", size=3, color = "red", angle=90)
```

The box plots clearly show that metropolitan areas have a lower median than the population, while non-metropolitan areas skew higher than the population as a whole.

```{r, warning=FALSE}
bind_rows(train_data %>% select(heart_disease_mortality_per_100k,
                      metro) %>%
  group_by(metro) %>%
  summarize(mn = mean(heart_disease_mortality_per_100k),
            md = median(heart_disease_mortality_per_100k)) %>%
  mutate(MeanAboveBelow = ifelse(round(mn,1) < hd_mean, 
                                 "Below",
                                 ifelse(round(mn,1) == hd_mean,
                                        "Equal", "Above")),
         MedianAboveBelow = ifelse(round(md,1) < hd_med,
                                   "Below",
                                   ifelse(round(md,1) == hd_med,
                                          "Equal", "Above"))) %>%
  select(population, mn, MeanAboveBelow, md, MedianAboveBelow)
  , data.frame(metro = "Population", 
               mn= hd_mean, 
               MeanAboveBelow = "",
               md = hd_med,
               MedianAboveBelow = "")
)
```

##### Air Pollution
Ambient air pollution for the county is presented in the data set as a measure of the concentration of fine particulate matter, as measured in µg/m^3^. These figures were presented as positive integers, so as a feature of the data set it is more akin to a categorical variable.  The initial spread of values showed a large discrepancy in population size, especially in the min and max regions (A), so values were grouped into a smaller number of populations that were closer in size (B)

```{r}
#Histogram for air pollution original
train_data %>% subset(!is.na(health__air_pollution_particulate_matter)) %>%
  ggplot(aes(x=health__air_pollution_particulate_matter))+
  geom_histogram(binwidth=1) + xlab("air pollution (mcg/m3)")+
  theme(axis.text.x = element_text(size=20))+
  ggtitle("(A)")+theme(plot.title = element_text(hjust=0.5))

#Histogram for air pollution regrouped
cut_labels <- c("<= 10", "11", "12", "13", "14+")
cut_levels <- c(0, 10.9, 11.9, 12.9, 13.9, 100)

train_data$air_pollution <- cut(train_data$health__air_pollution_particulate_matter, cut_levels)
levels(train_data$air_pollution) <- cut_labels

train_data %>% subset(!is.na(air_pollution)) %>%
  ggplot(aes(x=air_pollution))+
  geom_bar() + xlab("air pollution (mcg/m3)")+
  theme(axis.text.x = element_text(size=20))+
  ggtitle("(B)")+theme(plot.title = element_text(hjust=0.5))
```

Using the new groups, histograms and boxplots show the spreads to be approximately normal, with some groups skewing below the population mean and some above. The group with 12 µg/m^3^ shows a mean just at the population mean, with a median slightly lower.

```{r}
#Histograms by air pollution
plot <- ggplot(subset(train_data, !is.na(air_pollution)),
               aes(x=heart_disease_mortality_per_100k))+xlab("heart_mort_100k")+
  geom_histogram(binwidth = (high_mort-low_mort)/40)
plot <- plot+facet_wrap(~ air_pollution, drop=TRUE, ncol = 3)
plot <- plot+geom_vline(linetype="dashed", xintercept = hd_mean, color = "blue")
plot <- plot+geom_vline(linetype="dashed", xintercept = hd_med, color = "red")
plot <- plot + annotate("text", x=hd_mean+40, y=80, label="<- mean", size=2.5, color = "blue")
plot <- plot + annotate("text", x=hd_med-40, y=80, label="median ->", size=2.5, color = "red")
plot

#Box plot by air_pollution
plot <- ggplot(subset(train_data, !is.na(air_pollution)),
               aes(x=air_pollution, y=heart_disease_mortality_per_100k))+xlab("")+
  geom_boxplot()+ geom_hline(linetype="dashed", yintercept = hd_mean, color = "blue")
plot <- plot+geom_hline(linetype="dashed", yintercept = hd_med, color = "red")
plot <- plot + theme(axis.text.x = element_text(angle = 45, hjust=1, vjust=1)) + ggtitle("Air Pollution (mcg/m^3)")+theme(plot.title = element_text(hjust=0.5))
plot <- plot + annotate("text", x=.5, y=hd_mean+30, label="mean", size=3, color = "blue", angle=90)
plot <- plot + annotate("text", x=5.5, y=hd_med-30, label="median", size=3, color = "red", angle=90)
plot
```

A statistical summary of the air pollution groups confirms the interpretation of the histogram and box plots, and makes this feature a suitable candidate for a predictive model.

--do stuff with knitr or gridextra--

#### Correlation Between Numeric Features and Heart Disease Mortality
(note: all correlation calculations in this analysis are performed after data records with missing values for the feature in questions are removed)

##### Economic Factors
The remaining economic factors in the dataset (after already looking at typology) are numeric, so a correlation analysis is done to determine if any of these are candidates for use in a predictive model.
*	% Civilian Labor
*	% Unemployment
*	% Uninsured Adults
*	% Uninsured Children

```{r}
cols <- colnames(train_data)[like(colnames(train_data), "econ__pct")] 
ncol <- ifelse(length(cols) <= 6, 2, 3)

train_data %>% select(heart_disease_mortality_per_100k, cols) %>%
  gather(data_type, val, -heart_disease_mortality_per_100k) %>%
  mutate(data_type = substr(data_type, 7, 100)) %>%
  mutate(val= val*100) %>%
  ggplot(aes(x=val, y= heart_disease_mortality_per_100k))+geom_point(na.rm = TRUE)+
  facet_wrap(~ data_type, ncol=ncol, scales="free_x")+xlab("percent")+
  geom_smooth(method="lm", na.rm = TRUE)

data.frame(
  feature=names(train_data[cols]),
  corr = sapply(train_data[cols], function(x) {
    cor(data.frame(train_data$heart_disease_mortality_per_100k, x),
        use="complete.obs")[1,2] })
  ) %>% arrange(desc(abs(corr)))

```
```{r, echo=FALSE, eval=FALSE}
corr <- data.frame()
for (i in 1:length(cols)) {
  corr[cols[i],1] <- round(cor(data.frame(train_data$heart_disease_mortality_per_100k,
                              train_data[,cols[i]]),
                   use="complete.obs")[1,2],3)
}

corr <- cbind(cols, corr)
colnames(corr) <- c("type", "cor")
corr <- corr %>% mutate(type = substr(type, 7, 100)) %>% arrange(desc(abs(cor)))

corr %>% grid.table()


```

```{r, eval=FALSE, echo=FALSE}
#Correlation among econ stats
cname <- colnames(train_data)
cname <- cname[like(cname,"econ__pct")]

par(mfrow=c(2,2))

p = list()

for (i in 1:length(cname)) {

  #Determine correlation with default method
  cor <- round(cor(data.frame(train_data$heart_disease_mortality_per_100k,
                              train_data[,cname[i]]),
                   use="complete.obs")[1,2],3)
  cor <- paste("corr =", as.character(cor))
  
  #Plot econ factor vs mortality
    dplot <- ggplot(train_data, 
                  aes_string(y="heart_disease_mortality_per_100k",
                             x=cname[i]))+
    ylab("hrt_mort")+
    xlab(substr(cname[i], 7, 100))+
    xlim(0,max(train_data[cname[i]], na.rm=TRUE)+.05)
    
    if(cname[i]=="econ__pct_civilian_labor") {
      dplot <- dplot + theme(plot.background = element_rect(colour = "black", fill=NA, size=2))
    }


  p[[i]] <- dplot+geom_point(na.rm=TRUE)+
    geom_smooth(method="lm", se=TRUE, na.rm=TRUE)+
    annotate("text", x=max(train_data[cname[i]],na.rm=TRUE), y=500, label= cor, size=3)
}

do.call(grid.arrange, p)
```

As seen above, “Percent of Civilian Labor” shows a moderate negative correlation with heart disease mortality (despite the number of outliers appearing to be greater than the other factors) and is a good candidate for use in a predictive model.  The remaining factors do not show a strong enough correlation ( >= 0.45) to be considered good candidates.

##### Demographics
The dataset contains 12 demographic features that are reported as percentages of the population. A correlation analysis of those features in a similar manner to the economic factors. (NOTE: there are 2 numeric features that are represented as rates per 1000 people, and act more like categorical features as they are distinct whole numbers; a cursory exploration of these two factors was performed, but nothing of interest resulted from the exploration)

```{r}
cols <- colnames(train_data)[like(colnames(train_data), "demo__pct")] 
ncol <- ifelse(length(cols) <= 6, 2, 3)

train_data %>% select(heart_disease_mortality_per_100k, cols) %>%
  gather(data_type, val, -heart_disease_mortality_per_100k) %>%
  mutate(data_type = substr(data_type, 11, 100)) %>%
  mutate(val = val * 100) %>%
  ggplot(aes(x=val, y= heart_disease_mortality_per_100k))+geom_point(na.rm = TRUE)+
  facet_wrap(~ data_type, ncol=ncol, scales="fixed")+xlab("percent")+
  geom_smooth(method="lm", na.rm = TRUE)

data.frame(
  feature=names(train_data[cols]),
  corr = sapply(train_data[cols], function(x) {
    cor(data.frame(train_data$heart_disease_mortality_per_100k, x),
        use="complete.obs")[1,2] })
  ) %>% arrange(desc(abs(corr)))

```
```{r, echo=FALSE, eval=FALSE}
corr <- data.frame()
for (i in 1:length(cols)) {
  corr[cols[i],1] <- round(cor(data.frame(train_data$heart_disease_mortality_per_100k,
                              train_data[,cols[i]]),
                   use="complete.obs")[1,2],3)
}

corr <- cbind(cols, corr)
colnames(corr) <- c("type", "cor")
corr <- corr %>% mutate(type = substr(type, 7, 100)) %>% arrange(desc(abs(cor)))

corr %>% grid.table()

```


```{r, echo=FALSE, eval=FALSE}
#Correlation among demo stats
cname <- colnames(train_data)
cname <- cname[like(cname,"demo_")]
cname <- cname[!like(cname, "_1k")]

par(mfrow=c(3,4))

p = list()

for (i in 1:length(cname)) {
  #Determine correlation with default method
    cor <- round(cor(data.frame(train_data$heart_disease_mortality_per_100k,
                              train_data[,cname[i]]),
                   use="complete.obs")[1,2],3)
  cor <- paste("corr =", as.character(cor))

  #Plot demo vs mortality
  dplot <- ggplot(train_data, 
                  aes_string(y="heart_disease_mortality_per_100k",
                             x=cname[i]))+
                    ylab("hrt_mort")+
                    xlab(substr(cname[i], 11, 100)) #+
                    #xlim(0,1)
  if(cname[i] %in% c("demo__pct_non_hispanic_african_american",
                     "demo__pct_adults_less_than_a_high_school_diploma",
                     "demo__pct_adults_bachelors_or_higher")) {
      dplot <- dplot + theme(plot.background = element_rect(colour = "black", fill=NA, size=2))
  }

  p[[i]] <- dplot+geom_point(na.rm=TRUE)+
    geom_smooth(method="lm", se=TRUE, na.rm=TRUE)+
    annotate("text", x=.9, y=500, label= cor, size=2.5)+xlim(0, 1)
}

do.call(grid.arrange, p)
```

Analysis of the correlation scatter plots showed that there were several candidates for model features. “Percent of non-Hispanic African Americans” was chosen as it had the strongest correlation in the subset of race/ethnicity demographics, even though its actual correlation was only moderate ( < .45 ).  “Adults with less than a High School diploma” and “Adults with a Bachelor’s Degree or higher” were chosen for their strong positive and negative correlations, respectively.

The other two demographic categories related to education level (“High School Diploma”, “Some College”) were considered as features, but in practice they added no predictive power to the model. Two combination features, one of which added together “High School” and “Less than High School” and the other “Some College” and “Bachelor’s or higher” were considered as well.  While the combination features had higher correlations with heart disease mortality than the individual features, in practice the model seemed to suffer from overfitting when the combination features were used in place of the individual ones.

Because of their extremely weak correlations (abs value < .15), demographic features related to gender and age were not considered for the model.

#### Health Statistics
There are 10 more health-related factors present in the dataset (after air pollution). All are numerical, 6 are presented as percentage of the population, two are rates per 100,000 people, and two are rates related to the number of people per medical professional (primary care doctor, dentist).  The 2 features related to medical professional did not show a strong correlation ( > 0.45) to heart disease mortality rate, so they were not considered for the predictive model.

##### Health Percentages
A scatter plot and correlation analysis was done for the 6 numerical features presented as population percentages:

```{r}
cols <- colnames(train_data)[like(colnames(train_data), "health__pct")] 
ncol <- ifelse(length(cols) <= 6, 2, 3)

train_data %>% select(heart_disease_mortality_per_100k, cols) %>%
  gather(data_type, val, -heart_disease_mortality_per_100k) %>%
  mutate(data_type = substr(data_type, 9, 100)) %>%
  mutate(val = val * 100) %>%
  ggplot(aes(x=val, y= heart_disease_mortality_per_100k))+geom_point(na.rm = TRUE)+
  facet_wrap(~ data_type, ncol=ncol, scales="fixed")+xlab("percent")+
  geom_smooth(method="lm", na.rm = TRUE)

data.frame(
  feature=names(train_data[cols]),
  corr = sapply(train_data[cols], function(x) {
    cor(data.frame(train_data$heart_disease_mortality_per_100k, x),
        use="complete.obs")[1,2] })
  ) %>% arrange(desc(abs(corr)))

```
```{r, echo=FALSE, eval=FALSE}
corr <- data.frame()
for (i in 1:length(cols)) {
  corr[cols[i],1] <- round(cor(data.frame(train_data$heart_disease_mortality_per_100k,
                              train_data[,cols[i]]),
                   use="complete.obs")[1,2],3)
}

corr <- cbind(cols, corr)
colnames(corr) <- c("type", "cor")
corr <- corr %>% mutate(type = substr(type, 9, 100)) %>% arrange(desc(abs(cor)))

corr %>% grid.table()
```

```{r, eval=FALSE, echo=FALSE}
#Correlation among health stats
cname <- colnames(train_data)
cname <- cname[like(cname,"health__pct")]
#cname <- cname[!like(cname, "_1k")]

par(mfrow=c(4,3))

p = list()

for (i in 1:length(cname)) {
  #Calculate correlation between health pct and mortality
  cor <- round(cor(data.frame(train_data$heart_disease_mortality_per_100k,
                        train_data[,cname[i]]),
             use="complete.obs")[1,2],3)
  cor <- paste("corr =", as.character(cor))

  #Scatter plot
    dplot <- ggplot(train_data,
                  aes_string(y="heart_disease_mortality_per_100k",
                             x=cname[i]))+
    ylab("hrt_mort")+
    xlab(substr(cname[i], 9, 100))+
    xlim(0,.6)
  
  if(cname[i] %in% c("health__pct_adult_obesity",
                     "health__pct_adult_smoking",
                     "health__pct_diabetes",
                     "health__pct_physical_inacticity")) {
      dplot <- dplot + theme(plot.background = element_rect(colour = "black", fill=NA, size=2))
  }

  p[[i]] <- dplot+geom_point(na.rm=TRUE)+
    geom_smooth(method="lm", se=TRUE, na.rm=TRUE)+
    annotate("text", x=.5, y=500, label= cor, size=3.5)
}

do.call(grid.arrange, p)
```

Percent of Physical Inactivity shows the strongest correlation with heart disease mortality among the health percentages, indicating a strong candidate for the predictive model. Three other percentages (Obesity, Smoking, Diabetes) also showed strong correlation with heart disease mortality, but some further thought and analysis produced features with even stronger correlations.

##### Combining Health Percentages
Thinking about the 3 health percentages:
* Percent of adult obesity
* Percent of adult smoking
* Percent of diabetes
we can say that each of the percentages is the same as the probability of a randomly chosen individual in that county having the specific condition. Let us further assume that each of the events (being obese, smoking, having diabetes) are independent of each other. According to probability theory, the probability of two independent events occurring is simply the product of the two individual probabilities. Therefore

$$P(diabetes & obese) = P(diabetes) * P(obese)$$

$$P(diabetes & smoking) = P(diabetes) * P(smoking)$$

$$P(obese & smoking) = P (obese) * P(smoking)$$

$$P(obese & smoking & diabetes) = P(obese) * P(smoking) * P(diabetes)$$

By calculating these combined probabilities, we find features that have even stronger correlation that each individual feature
```{r}
train_data <- train_data %>% 
  mutate(p_diab_obese = health__pct_adult_obesity * health__pct_diabetes) %>%
  mutate(p_diab_smoke = health__pct_diabetes * health__pct_adult_smoking) %>%
  mutate(p_obese_smoke = health__pct_adult_smoking * health__pct_adult_obesity) %>%
  mutate(p_all_three = health__pct_adult_obesity * health__pct_adult_obesity * health__pct_adult_smoking )
```
```{r}
cols <- c("p_diab_obese", 
          "p_diab_smoke", 
          "p_obese_smoke", 
          "p_all_three")

ncol <- ifelse(length(cols) <= 6, 2, 3)

train_data %>% select(heart_disease_mortality_per_100k, cols) %>%
  gather(data_type, val, -heart_disease_mortality_per_100k) %>%
  mutate(data_type = substr(data_type, 3, 100)) %>%
  mutate(val = val * 100) %>%
  ggplot(aes(x=val, y= heart_disease_mortality_per_100k))+geom_point(na.rm = TRUE)+
  facet_wrap(~ data_type, ncol=ncol, scales="fixed")+xlab("percent")+
  geom_smooth(method="lm", na.rm = TRUE)
```
```{r, echo=FALSE}
data.frame(
  feature=names(train_data[cols]),
  corr = sapply(train_data[cols], function(x) {
    cor(data.frame(train_data$heart_disease_mortality_per_100k, x),
        use="complete.obs")[1,2] })
  ) %>% arrange(desc(abs(corr)))

```
```{r, echo=FALSE}
corr <- data.frame()
for (i in 1:length(cols)) {
  corr[cols[i],1] <- round(cor(data.frame(train_data$heart_disease_mortality_per_100k,
                              train_data[,cols[i]]),
                   use="complete.obs")[1,2],3)
}

corr <- cbind(cols, corr)
colnames(corr) <- c("type", "cor")
corr <- corr %>% mutate(type = substr(type, 3, 100)) %>% arrange(desc(abs(cor)))

corr %>% grid.table()
```

The 3 combinations with the strongest correlations ( > 0.64) are good candidates for the predictive model (Diab+Obese, Diab+Smoke, All Three). In practice, Obese+Smoke did not add any predictive power to the model, so it was omitted.

####Death Rates
Homicide rate and Motor Vehicle Death rate (both per 100,000 individuals) each showed moderate correlation with heart disease mortality (0.441 and 0.460, respectively). However, when each factor was converted to a log10 scale, the correlation got stronger (.501, .504, respectively).

```{r, warning=FALSE}
train_data$log_homicide_per_100k <-
  ifelse(train_data$health__homicides_per_100k <= 0, NA,
         log10(train_data$health__homicides_per_100k))
train_data$log_motor_vehicle_death_per_100k <-
  log10(train_data$health__motor_vehicle_crash_deaths_per_100k)

train_data <- train_data %>%
  mutate(death_rate_motor_vehicle_crash_per_100k = health__motor_vehicle_crash_deaths_per_100k,
         death_rate_homicides_per_100k = health__homicides_per_100k)

cols <- c("death_rate_homicides_per_100k", 
          "death_rate_motor_vehicle_crash_per_100k",
          "log_homicide_per_100k",
          "log_motor_vehicle_death_per_100k")

ncol <- 2

train_data %>% select(heart_disease_mortality_per_100k, cols) %>%
  gather(data_type, val, -heart_disease_mortality_per_100k) %>%
  ggplot(aes(x=val, y= heart_disease_mortality_per_100k))+geom_point(na.rm = TRUE)+
  facet_wrap(~ data_type, ncol=ncol, scales="free_x")+xlab("per_100k")+
  geom_smooth(method="lm", na.rm = TRUE)
```
```{r, echo=FALSE}
corr <- data.frame()
for (i in 1:length(cols)) {
  corr[cols[i],1] <- round(cor(data.frame(train_data$heart_disease_mortality_per_100k,
                              train_data[,cols[i]]),
                   use="complete.obs")[1,2],3)
}

corr <- cbind(cols, corr)
colnames(corr) <- c("type", "cor")
corr <- corr %>% arrange(desc(abs(cor)))

corr %>% grid.table()
```

Each version was used in separate iterations of the predictive model, and surprisingly, the “base” version (prior to log10 conversion) showed marginally better predictive power.

##Data Preparation for Predictive Modelling
The features chosen for use in the predictive model are

* Economic Typology (categorical)
* Population (categorical)
* Metropolitan Type (categorical)
* Air Pollution concentration (categorical)
* Percent of Civilian Labor (numeric)
* Percent non-Hispanic African American (numeric)
* Percent of Adult Physical Inactivity (numeric)
* Percent of adults with less than a High School diploma (numeric)
* Percent of adults with Bachelor’s Degree or higher (numeric)
* Percent of adults that are obese and have diabetes (numeric)
* Percent of adults that smoke and have diabetes (numeric)
* Percent of adults that are obese, smoke, and have diabetes (numeric)
* Homicides per 100,000 individuals (numeric)
* Motor vehicle crash deaths per 100,000 individuals (numeric)

In order to take advantage of predictive models in R, missing values need to be handled. The two choices would be to either remove rows with missing data, or to replace missing values with a constant value based on the characteristics of the feature.

###Numeric data
First we look at the number of records in the entire data set that are missing at least one of the chosen predictors

```{r}
model_cols <- c("econ__economic_typology",
                "population", 
                "metro",
                "air_pollution",
                "econ__pct_civilian_labor",
                "demo__pct_non_hispanic_african_american",
                "demo__pct_adults_bachelors_or_higher",
                "demo__pct_adults_less_than_a_high_school_diploma",
                "p_diab_obese",
                "p_diab_smoke",
                "p_all_three",
                "health__homicides_per_100k",
                "health__motor_vehicle_crash_deaths_per_100k")

cont_cols <- model_cols[-c(1:4)]

#How many rows have at least 1 missing numeric value?
mval <- function(x) {
  this_row <- train_data %>% filter(row_id==x) %>% 
    select(row_id, cont_cols) %>% as.vector()
  ifelse(length(which(is.na(this_row)))>0, this_row[1], 0)
}

missval <- sapply(train_data$row_id, mval, simplify = TRUE)

mean(missval!=0)  ##Percentage of rows with missing values

```

We see that well over 50% of the records have at least one numeric feature missing. This means that eliminating the records with missing data is not feasible. So the next step is to determine if a small number of predictors is contributing the majority of the missing values, in which case we can remove the predictor.

```{r}
#Which features have most NAs
data.frame(
  NA_pct = sapply(train_data[cont_cols],
                  function(x){mean(ifelse(is.na(x), 1, 0))},
                  simplify=TRUE))
```


which value, per feature, makes the most sense as a substitute. Using the MEAN value of the feature makes sense if the data is relatively normal, while MEDIAN would work best for highly skewed data.  We produce histograms showing the distribution, mean and median for the numeric features to examine the normalcy:

```{r, warning=FALSE}
feat_means <- train_data %>% select(cont_cols) %>%
  gather(feature, value) %>% group_by(feature) %>%
  mutate(mn = mean(value, na.rm=TRUE), 
         md = median(value, na.rm=TRUE))

train_data %>% select(cont_cols) %>%
  gather(feature, value) %>%
  ggplot(aes(x=value)) + geom_histogram() +
  geom_vline(aes(xintercept=mn), 
             data = feat_means, linetype = "dashed", 
             color = "green")+
  geom_vline(aes(xintercept=md), 
             data = feat_means, linetype = "dashed", 
             color = "red")+
  facet_wrap(~ feature, scales="free") +
  xlab("green = mean; red = median")
```

For all features except for Percent of Civilian Labor, the data is skewed positive, and the median is not insignificantly different (lower) than the mean. So replacing NA values with the MEDIAN of the population would introduce the least bias to the data.

```{r}
#Replace NA with column median
train_data <- train_data %>%
  mutate_at(cont_cols, 
            ~ifelse(is.na(.x), median(.x, na.rm = TRUE), .x))

```

###Categorical
The number of records with NA in the categorical features is much different

```{r}
mval <- function(x) {
  this_row <- train_data %>% filter(row_id==x) %>% 
    select(row_id, model_cols[1:4]) %>% as.vector()
  ifelse(length(which(is.na(this_row)))>0, this_row[1], 0)
}

missval_c <- sapply(train_data$row_id, mval, simplify = TRUE)

length(which(missval_c!=0))
```

As less than 1% of records in the data set have NA in a chosen categorical feature, the best approach is to remove those records from the data set.

```{r}
train_data <- train_data[which(missval_c==0),]
```


